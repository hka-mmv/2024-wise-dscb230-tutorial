{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 1: Programme zur Datenauswertung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemein\n",
    "\n",
    "Die Datenauswertung ist ein Prozess, bei dem Rohdaten systematisch analysiert werden, um daraus wertvolle Informationen und Erkenntnisse zu gewinnen. Mithilfe verschiedener Methoden und statistischer Verfahren werden diese Daten untersucht, beschrieben und schließlich in Form von Kennzahlen und Visualisierungen übersichtlich präsentiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial: Hilfreiche Python-Bibliotheken für die Datenauswertung\n",
    "\n",
    "Glücklicherweise existieren Bibliotheken, welche uns die Datenauswertung stark erleichtern. Darunter:\n",
    "- **SciPy:** Bietet eine Sammlung von Algorithmen und Funktionen für wissenschaftliche Berechnungen, einschließlich Statistik, Optimierung, Interpolation und Signalverarbeitung.\n",
    "- **Scikit-learn:** Bietet eine Vielzahl von Algorithmen für maschinelles Lernen, einschließlich Klassifizierung, Regression, Clustering und Dimensionsreduktion.\n",
    "- **Statsmodels:** Bietet eine umfassende Sammlung von statistischen Modellen und Tests, einschließlich linearer Regression, Zeitreihenanalyse und Hypothesentests.\n",
    "- **Seborn:** Bietet eine auf Matplotlib aufbauende Bibliothek für die Erstellung von ansprechenden statistischen Grafiken.\n",
    "- **Plotly:** Bietet eine interaktive Plotting-Bibliothek für die Erstellung von dynamischen und webbasierten Diagrammen.\n",
    "- **Bokeh:** Bietet eine weitere interaktive Plotting-Bibliothek für die Erstellung von interaktiven Visualisierungen in Webanwendungen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zusätzliche Hinweise\n",
    "\n",
    "- Für die Installation der Bibliotheken kann der Paketmanager `pip` verwendet werden (z. B. `pip install pandas numpy matplotlib`).\n",
    "- Es empfiehlt sich, die Dokumentation der Bibliotheken zu konsultieren, um sich mit den verfügbaren Funktionen und Methoden vertraut zu machen.\n",
    "- Experimentieren Sie mit verschiedenen Bibliotheken und Visualisierungstechniken, um die für Ihre Datenanalyse am besten geeigneten zu finden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einführung in die verwendeten Bibliotheken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy\n",
    "\n",
    "NumPy ist eine Python-Bibliothek für wissenschaftliches Rechnen. Sie bietet:\n",
    "- **N-dimensionale Arrays:** Die Hauptstruktur von NumPy ist das ndarray (N-dimensionales Array), welches eine effiziente Möglichkeit zur Speicherung und Bearbeitung großer Datenmengen bietet.\n",
    "- **Mathematische Funktionen:** NumPy bietet eine breite Palette an mathematischen Funktionen, die auf Arrays angewendet werden können, wie z. B. trigonometrische Funktionen, lineare Algebra, Zufallszahlen und mehr.\n",
    "- **Werkzeuge zur Array-Manipulation:** NumPy bietet Werkzeuge zum Ändern der Form, Größe und Anordnung von Arrays.\n",
    "\n",
    "**Beispiele:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Array erstellen\n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "print(a)  # Ausgabe: [1 2 3 4 5]\n",
    "\n",
    "# Array mit Nullen erstellen\n",
    "b = np.zeros(5)\n",
    "print(b)  # Ausgabe: [0. 0. 0. 0. 0.]\n",
    "\n",
    "# Array mit Einsen erstellen\n",
    "c = np.ones((2, 3))\n",
    "print(c)  # Ausgabe: [[1. 1. 1.]\n",
    "          #          [1. 1. 1.]]\n",
    "\n",
    "# Array mit Zufallszahlen erstellen\n",
    "d = np.random.rand(3, 2)\n",
    "print(d)  # Ausgabe: z. B. [[0.123 0.456]\n",
    "          #                [0.789 0.111]\n",
    "          #                [0.222 0.333]]\n",
    "\n",
    "# Mathematische Operationen\n",
    "print(a + 2)  # Ausgabe: [3 4 5 6 7]\n",
    "print(a * 3)  # Ausgabe: [3 6 9 12 15]\n",
    "print(np.sin(a))  # Ausgabe: Sinuswerte der Elemente in a\n",
    "\n",
    "# Array-Manipulation\n",
    "print(a.reshape(1, 5))  # Ausgabe: [[1 2 3 4 5]]\n",
    "print(a.transpose())  # Ausgabe: [1 2 3 4 5] (bei 1D-Array keine Änderung)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas\n",
    "\n",
    "Pandas ist eine Bibliothek, die Datenstrukturen und Funktionen für die Datenanalyse bereitstellt. Die wichtigsten Datenstrukturen sind:\n",
    "\n",
    "- **Series:** Ein eindimensionales Array, das Daten eines bestimmten Typs (z. B. Zahlen, Strings) enthält.\n",
    "- **DataFrame:** Eine zweidimensionale Tabelle mit Spalten, die jeweils eine Series darstellen. DataFrames sind die zentrale Datenstruktur in Pandas und ähneln Tabellen in einer Datenbank oder einer Spreadsheet-Anwendung.\n",
    "\n",
    "**Beispiele:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# DataFrame erstellen\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"Alter\": [25, 30, 28],\n",
    "    \"Stadt\": [\"Berlin\", \"München\", \"Hamburg\"]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# Zugriff auf Spalten\n",
    "print(df[\"Name\"])  # Ausgabe: Namensspalte als Series\n",
    "print(df.Alter)  # Alternative Schreibweise\n",
    "\n",
    "# Zugriff auf Zeilen\n",
    "print(df.iloc[0])  # Ausgabe: Erste Zeile als Series\n",
    "print(df.loc[df[\"Name\"] == \"Alice\"])  # Zeilen mit Name \"Alice\"\n",
    "\n",
    "# Neue Spalte hinzufügen\n",
    "df[\"Gehalt\"] = [50000, 60000, 55000]\n",
    "print(df)\n",
    "\n",
    "# Daten filtern\n",
    "print(df[df[\"Alter\"] > 28])  # Zeilen mit Alter größer 28\n",
    "\n",
    "# Daten sortieren\n",
    "print(df.sort_values(by=\"Alter\", ascending=False))  # Nach Alter absteigens sortieren\n",
    "\n",
    "# Aggregatfunktionen\n",
    "print(df[\"Gehalt\"].mean())  # Durchschnittsgehalt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matplotlib\n",
    "\n",
    "Matplotlib ist die Standardbibliothek von statischen, interaktiven und animierten Visualisierungen in Python. Sie bietet eine große Auswahl an Diagrammtypen und Anpassungsmöglichkeiten.\n",
    "\n",
    "**Beispiele**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Liniendiagramm\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [2, 4, 6, 8, 10]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"X-Achse\")\n",
    "plt.ylabel(\"Y-Achse\")\n",
    "plt.title(\"Liniendiagramm\")\n",
    "plt.show()\n",
    "\n",
    "# Streudiagramm\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [2, 1, 4, 3, 5]\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"X-Achse\")\n",
    "plt.ylabel(\"Y-Achse\")\n",
    "plt.title(\"Streudiagramm\")\n",
    "plt.show()\n",
    "\n",
    "# Balkendiagramm\n",
    "x = [\"A\", \"B\", \"C\", \"D\"]\n",
    "y = [10, 20, 15, 25]\n",
    "\n",
    "plt.bar(x, y)\n",
    "plt.xlabel(\"Kategorien\")\n",
    "plt.ylabel(\"Werte\")\n",
    "plt.title(\"Balkendiagramm\")\n",
    "plt.show()\n",
    "\n",
    "# Histogramm\n",
    "data = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5]\n",
    "\n",
    "plt.hist(data, bins=5)\n",
    "plt.xlabel(\"Werte\")\n",
    "plt.ylabel(\"Häufigkeit\")\n",
    "plt.title(\"Histogramm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciPy\n",
    "\n",
    "SciPy baut auf NumPy auf und bietet eine große Sammlung von Algorithmen und Funktionen für wissenschaftliche Berechnungen. Einige wichtige Bereiche sind:\n",
    "\n",
    "- **Statistik:** Funktionen für desktiptive Statistik, Wahrscheinlichkeitsverteilungen, Hypothesentests und mehr.\n",
    "- **Optimierung:** Algorithmen zur Minimierung oder Maximierung von Funktionen.\n",
    "- **Interpolation:** Methoden zur Approximation von Funktionswerten zwischen bekannten Datenpunkten.\n",
    "- **Signalverarbeitung:** Funktionen zur Filterung, Transformation und Analyse von Signalen.\n",
    "- **Lineare Algebra:** Erweiterte Funktionen für lineare Algebra, die über NumPy hinausgehen.\n",
    "- **Integration:** Numerische Integration von Funktionen.\n",
    "\n",
    "**Beispiele:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "# Normalverteilung\n",
    "x = np.linspace(-3, 3, 100)\n",
    "y = stats.norm.pdf(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title(\"Normalverteilung\")\n",
    "plt.show()\n",
    "\n",
    "# T-Test\n",
    "data1 = [1, 2, 3, 4, 5]\n",
    "data2 = [2, 3, 4, 5, 6]\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(data1, data2)\n",
    "\n",
    "print(f\"T-Statistik: {t_statistic}\")\n",
    "print(f\"P-Wert: {p_value}\")\n",
    "\n",
    "# Optimierung\n",
    "def f(x):\n",
    "    return x ** 2 + 2 * x + 1\n",
    "\n",
    "result = minimize_scalar(f)\n",
    "print(result.x)  # Ausgabe: -1.0 (Minimum der Funktion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-learn\n",
    "\n",
    "Scikit-learn ist eine Bibliothek für maschinelles Lernen in Python. Sie bietet eine Vielzahl von Algorithmen für:\n",
    "- **Klassifizierung:** Zuweisung von Datenpunkten zu Kategorien.\n",
    "- **Regression:** Vorhersaage von kontinuierlichen Werten.\n",
    "- **Clustering:** Gruppierung von Datenpunkten in Cluster.\n",
    "- **Dimensionsreduktion:** Reduzierung der Anzahl von Merkmalen in einem Datensatz.\n",
    "- **Modellselektion:** Auswahl des besten Modells für einen bestimmten Datensatz.\n",
    "- **Vorverarbeitung:** Transformation von Daten in ein geeignetes Format für maschinelles Lernen.\n",
    "\n",
    "**Beispiele:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Lineare Regression\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([2, 4, 6, 8, 10])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # Daten aufteilen in Trainings- und Testdaten\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)  # Modell trainieren\n",
    "\n",
    "y_pred = model.predict(X_test)  # Vorhersage auf Testdaten\n",
    "\n",
    "# Bewertung des Modells\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mittlerer quadratischer Fehler: {mse}\")\n",
    "\n",
    "# Klassifizierung mit Support Vector Machines\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(model.predict([[2., 2.]]))  # Ausgabe: [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statsmodels\n",
    "\n",
    "Statsmodels ist eine Bibliothek, die eine umfassende Sammlung von statistischen Modellen und Tests bereitstellt. Sie wird häufig für die ökonomische Modellierung, Zeitreihenanalyse und statistische Inferenz verwendet. Einige wichtige Funktionen sind:\n",
    "\n",
    "- **Lineare Regression:** Ordinary Least Squares (OLS), Generalized Least Squares (GLS), Weighted Least Squares (WLS)\n",
    "- **Zeitreihenanalyse:** ARIMA, VAR, ARCH, GARCH\n",
    "- **Verallgemeinerte lineare Modelle (GLM):** Logistische Regression, Poisson-Regression\n",
    "- **Robuste Regression:** RANSAC, Huber Regression\n",
    "- **Hypothesentests:** t-Tests, F-Tests, $\\chi^2$-Tests\n",
    "- **Nichtparametrische Methoden:** Kernel Density Estimation, Local Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Lineare Regression\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "X = sm.add_constant(X)  # Konstante hinzufügen\n",
    "\n",
    "model = sm.OLS(y, X) \n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())  # Detaillierte Ausgabe der Regressionsergebnisse\n",
    "\n",
    "# Zeitreihenanalyse (ARIMA)\n",
    "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "model = ARIMA(data, order=(5, 1, 0))  # ARIMA(p, d, q) Modell\n",
    "\n",
    "model_fit = model.fit()\n",
    "\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seaborn\n",
    "\n",
    "Seaborn ist eine Bibliothek, die auf Matplotlib aufbaut und die Erstellung von ansprechenden statistischen Grafiken vereinfacht. Seaborn bietet:\n",
    "\n",
    "- **High-Level-Schnittstelle:** Einfacheres Erstellen von komplexen Diagrammen mit weniger Code.\n",
    "- **Statistische Visualisierungen:** Diagramme, die statistische Beziehungen zwischen Variablen hervorheben, wie z. B. Scatterplots mit Regressionsgeraden, Violinplots, Heatmaps.\n",
    "- **Integration mit Pandas:** Direkte Verwendung von Pandas DataFrames für die Datenvisualisierung.\n",
    "- **Ästhetische Anpassungen:** Einfache Anpassung von Farben, Stilen und Layouts.\n",
    "\n",
    "**Beispiele:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Scatterplot mit Regressionsgerade\n",
    "data = {\n",
    "    \"x\": [1, 2, 3, 4, 5],\n",
    "    \"y\": [2, 1, 4, 3, 5]\n",
    "}\n",
    "sns.regplot(x=\"x\", y=\"y\", data=data)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Violinplot\n",
    "data = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5]\n",
    "sns.violinplot(data)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Heatmap\n",
    "data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "sns.heatmap(data, annot=True)  # Werte anzeigen\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotly\n",
    "\n",
    "Plotly ist eine Bibliothek für die Erstellung von interaktiven, webbasierten Diagrammen. Plotly bietet:\n",
    "\n",
    "- **Interaktive Diagramme:** Diagramme, die durch Zoomen, Schwenken, Hover-Effekte und andere Interaktionen erkundet werden können.\n",
    "- **Vielfältige Diagrammtypen:** Eine große Auswahl an Diagrammtypen, einschließlich 3D-Diagramme, Karten und wissenschaftliche Diagramme.\n",
    "- **Export in verschiedene Formate:** Diagramme können als statische Bilder oder als interaktive HTML-Dateien exportiert werden.\n",
    "- **Integration mit Dash:** Plotly kann mit Dash, einem Framework zum Erstellen von interaktiven Webanwendungen, kombiniert werden. Dash ermöglicht es, interaktive Dashboards und Webanwendungen zu erstellen, die Plotly-Diagramme und andere interaktive Komponenten enthalten.\n",
    "\n",
    "**Beispiele:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Scatterplot\n",
    "data = {\n",
    "    \"x\": [1, 2, 3, 4, 5],\n",
    "    \"y\": [2, 1, 4, 3, 5]\n",
    "}\n",
    "\n",
    "fig = px.scatter(data, x=\"x\", y=\"y\")\n",
    "fig.show()\n",
    "\n",
    "# Balkendiagramm\n",
    "data = {\n",
    "    \"x\": [\"A\", \"B\", \"C\", \"D\"],\n",
    "    \"y\": [10, 20, 15, 25]\n",
    "}\n",
    "\n",
    "fig = px.bar(data, x=\"x\", y=\"y\")\n",
    "fig.show()\n",
    "\n",
    "# 3D-Scatterplot\n",
    "data = {\n",
    "    \"x\": [1, 2, 3, 4, 5],\n",
    "    \"y\": [2, 1, 4, 3, 5],\n",
    "    \"z\": [3, 4, 2, 1, 5]\n",
    "}\n",
    "\n",
    "fig = px.scatter_3d(data, x=\"x\", y=\"y\", z=\"z\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bokeh\n",
    "\n",
    "Bokeh ist eine weitere Bibliothek für die Erstellung von interaktiven Visualisierungen in Python. Bokeh konzentriert sich auf:\n",
    "\n",
    "- **Streaming-Daten:** Visualisierung von Daten, die sich im Laufe der Zeit ändern.\n",
    "- **Große Datensätze:** Effiziente Darstellung großer Datensätze.\n",
    "- **Anpassbare Interaktionen:** Möglichkeit, benutzerdefinierte Interaktionen mit Diagrammen zu erstellen.\n",
    "- **Integration mit Webanwendungen:** Einfache Einbettung von Bokeh-Diagrammen in Webanwendungen.\n",
    "\n",
    "**Beispiele:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "\n",
    "# Liniendiagramm\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [2, 4, 6, 8, 10]\n",
    "\n",
    "p = figure(title=\"Liniendiagramm\", x_axis_label=\"x\", y_axis_label=\"y\")\n",
    "p.line(x, y, legend_label=\"Linie\", line_width=2)\n",
    "\n",
    "show(p)\n",
    "\n",
    "# Interaktiver Scatterplot\n",
    "data = {\n",
    "    \"x\": [1, 2, 3, 4, 5],\n",
    "    \"y\": [2, 1, 4, 3, 5],\n",
    "    \"name\": [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "}\n",
    "\n",
    "source = ColumnDataSource(data)\n",
    "\n",
    "p = figure(title=\"Interaktiver Scatterplot\", x_axis_label=\"x\", y_axis_label=\"y\")\n",
    "p.circle(x=\"x\", y=\"y\", source=source, size=10, legend_label=\"Punkte\")\n",
    "\n",
    "hover = HoverTool(tooltips=[(\"Name\", \"@name\")])  # Hover-Effekt\n",
    "p.add_tools(hover)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zusätzliche Hinweise zu den Bibliotheken:\n",
    "\n",
    "- Die hier gezeigten Beispiele sind nur ein kleiner Ausschnitt der Möglichkeiten, die die Bibliotheken bieten.\n",
    "- Es empfiehlt sich, die Dokumentation der Bibliotheken zu konsultieren, um sich mit allen Funktionen und Optionen vertraut zu machen. Dies wird zum Teil bei dem Anwendungsfall auch nötig sein, sollten Sie nicht bereits über die entsprechenden Kenntnisse verfügen.\n",
    "- Experimentieren Sie mit verschiedenen Bibliotheken und Diagrammtypen, um die für Ihre Datenanalyse am besten geeigneten zu finden.\n",
    "- Sie werden nicht alle der genannten Bibliotheken in diesem Anwendungsfall benötigen. Sie können jedoch die nicht verwendeten Bibliotheken nutzen, wenn Sie an dem Datensatz noch weiter arbeiten möchten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Beginn des Anwendungsfalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausgangssituation\n",
    "\n",
    "Ihnen ist der MPG-Datensatz gegeben.\n",
    "\n",
    "Der MPG-Datensatz enthält Informationen über den Kraftstoffverbrauch (miles per gallon, mpg) von 398 verschiedenen Fahrzeugmodellen aus den Jahren 1970 bis 1982. Zu den Fahrzeugmerkmalen gehören unter anderem:\n",
    "\n",
    "- Anzahl der Zylinder (cylinders)\n",
    "- Hubraum (displacement)\n",
    "- Leistung (horsepower)\n",
    "- Gewicht (weight)\n",
    "- Beschleunigung (acceleration)\n",
    "- Modelljahr (model_year)\n",
    "- Herkunftsland (origin)\n",
    "- Fahrzeugname (name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diesen Datensatz gilt es nun von verschiedenen Perspektiven zu durchleuchten und zu analysieren.\n",
    "\n",
    "Beginnen wir einmal damit, den Datensatz zu laden, die Rohdaten zu betrachten, nach ersten Erkenntnissen zu suchen und erste Maßnahmen zu ergreifen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(\"mpg\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kann erkennen, dass die Spalte `name` ziemlich Anfällig für Redundanzen ist, da sie von jedem gespeicherten Auto sowohl den Modellnamen als auch den Namen des jeweiligen Herstellers speichert. Behalten wir dies einmal im Hinterkopf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein `pandas.DataFrame` kann grundlegende Informationen zu seinen Spalten anzeigen und für seine numerischen Spalten ein paar grundlegende Größen der deskriptiven Statistik berechnen. Dafür nutzen wir jeweils `pandas.DataFrame.info()` und `pandas.DataFrame.describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ihnen sollte aufgefallen sein, dass die Spalte `horsepower` über \"_392 non-null_\"-Werte verfügt. Im Klartext bedeutet dies, dass in der Spalte `horsepower` 392 von 398 Zeilen nicht `null` bzw. nicht `None` sind.\n",
    "\n",
    "Behalten Sie sich auch dies einmal im Hinterkopf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus diesem DataFrame lässt sich einiges erkennen, aber für den Anfang können wir erstmal beispielhaft eine Kleinigkeit hervorheben: Das 75%-Quantil der Anzahl der Zylinder ist 8 - mit anderen Worten: die oberen 75% der eingetragenen Autos haben durchschnittlich 8 Zylinder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uns sind bislang zwei Unüblichkeiten aufgefallen und es hat den Anschein, als würden wir ohne weiteres nichts neues finden. Nun ist es also an der Zeit mit der **Datenvorverarbeitung** zu beginnen.\n",
    "\n",
    "Bei der Datenvorverarbeitung untersuchen wir die Daten hinsichtlich ihrer Qualität und ergreifen Maßnahmen, um Datenqualitätsmängel zu beseitigen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Behandlung der fehlenden Werte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben bereits festgestellt, dass in der Spalte `horsepower` Einträge existieren, die keinen Wert aufweisen. Fehlende Werte kennzeichnet Pandas mit NaN (Not a Number).\n",
    "\n",
    "Wie im Tutorial bereits gezeigt, können wir in einem DataFrame selektieren. Selektieren wir einmal alle Zeilen, in welchen `horsepower` einen NaN-Wert enthält:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"horsepower\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus der Vorlesung sollte Ihnen bekannt sein, dass wir NaN-Werte auf eine der folgenden Weisen behandeln können:\n",
    "\n",
    "- Betroffene Zeilen aus dem Datensatz löschen\n",
    "- NaN-Werte durch repräsentativen Wert (Mean, Median, Modus, etc.) ersetzen\n",
    "- NaN-Werte ignorieren\n",
    "- NaN-Werte als separate Kategorien behandeln (bei kategorischen Features)\n",
    "\n",
    "Damit wir erstmal alle Modelle im Datensatz behalten und gleichzeitig sinnvoll analysieren können, ersetzen wir die fehlenden Werte einmal durch den Mean der Spalte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horsepower_mean = df[\"horsepower\"].mean()\n",
    "df.fillna({\"horsepower\": horsepower_mean}, inplace=True)  # inplace=True sorgt dafür, dass die Änderung ohne manuelle Zuweisung der Variable übernommen wird\n",
    "\n",
    "print(f\"Anzahl NaN-Werte in der Spalte 'horsepower' {df[df[\"horsepower\"].isna()].size}\")  # size ist die Anzahl der Zeilen eines DataFrames\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit wären die Nan-Werte behandelt und es existieren auch keine weiteren NaN-Werte in diesem DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erinnern Sie sich noch daran, dass die Spalte `name` anfällig für Redundanzen ist? Falls ja, sehr gut! Falls nicht, jetzt wissen Sie es wieder. Behalten Sie sich diese Info noch etwas länger im Hinterkopf, denn darum kümmern wir uns etwas später. Jetzt möchten wir uns erstmal mit den Daten auseinandersetzen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrachten wir zunächst nochmals den DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine naheliegende Schlussfolgerung wäre, dass schwerere Autos einen höheren Kraftstoffverbrauch aufweisen. Aber bilden die Daten dies auch so ab?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hängt der Kraftstoffverbrauch davon ab, wie schwer ein Fahrzeug ist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sie kennen aus der deskriptiven Statistik den Korrelationskoeffizienten. Dieser zeigt den linearen Zusammenhang zwischen zwei oder mehr Variablen. Würden wir den Korrelationskoeffizienten für die Spalten `mpg` und `weight` ausrechnen würden wir dies folgendermaßen umsetzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"mpg\", \"weight\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ergebnis ein negativer Korrelationskoeffizient mit Betrag nahe an $1$. Dies bedeutet, dass es einen relativ starken, negativen linearen Zusammenhang zwischen den Variablen `mpg` und `weight` gibt. Ein negativer Zusammenhang bedeutet, dass ein Anstieg des Wertes der einen Variable zu einer Reduktion des Wertes der anderen führt und umgekehrt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da jedoch eine Tabelle mit irgendwelchen Zahlen nicht wirklich schön aussieht, möchten wir das Ganze einmal visualisieren. Der Einfachheit wegen, nutzen wir hierfür Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(\n",
    "    data_frame=df,\n",
    "    x=\"weight\",\n",
    "    y=\"mpg\",\n",
    "    title=\"Zusammenhang zwischen Gewicht und Reichweite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabei steht jeder Punkt in diesem Streudiagramm jeweils für ein Auto aus `df`. Man kann erkennen, dass tatsächlich eine Tendenz, wie eben beschrieben existiert. Um diese Tendenz zu verdeutlichen, können wir dem Diagramm noch eine Trendlinie hinzufügen, was zwar nicht zwingend notwendig ist, aber in manchen Fällen kann eine Trendlinie sinnvoll sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    data_frame=df,\n",
    "    x=\"weight\",\n",
    "    y=\"mpg\",\n",
    "    trendline=\"ols\",\n",
    "    title=\"Zusammenhang zwischen Gewicht und Reichweite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aber was, wenn die Reichweite nicht nur vom Gewicht abhängt oder das Gewicht noch von anderen Variablen abhängt? Um solche Fragen zu beantworten, können wir die Analyse auf mehrere Features ausweiten. Dies können Sie als eigenständige Aufgabe machen, falls Sie Lust darauf haben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrachten wir den DataFrame erneut und suchen nach weiteren Dingen, die man analysieren könnte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lassen Sie uns einmal folgende Frage beantworten:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Welche Zylinder-Anzahl wurde in den jeweiligen Regionen (`origin`) im Durchschnitt hergestellt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas bietet - wie `SQL` - die Möglichkeit, nach Spalten zu gruppieren und zu aggregieren. Bevor Sie weitergehen, überlegen Sie sich, wie Sie diese Frage in `SQL` beantworten würden. Überlegen Sie auch, welche Aggregatsfunktion am besten geeignet ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby(\"origin\")[\"cylinders\"].mean()\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erkenntnis:** In Europa und in Japan wurden durchschnittlich 4-Zylinder hergestellt und in den USA 6-Zylinder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Welche Zylinder-Anzahl wurde in den jeweiligen Regionen wie oft hergestellt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier würden Sie so ähnlich vorgehen wie gerade eben, nur mit dem Unterschied, dass Sie nach zwei Attributen gruppieren müssten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby([\"origin\", \"cylinders\"]).agg(cylinder_count=(\"cylinders\", \"count\"))\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kann erkennen, dass Europa und Japan die 4-Zylinder stark favorisierten, während es bei den USA etwas ausgeglichener ist, wobei hier eine klare Präferenz zu den 8-Zylindern sichtbar ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Thema mit den Regionen kann man auch wieder für weitere Analysen verwenden. Dies können Sie selbst tun, falls Sie Lust darauf haben, sich mit den Daten genauer zu beschäftigen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun, da Sie zumindest ein grobes Gefühl dafür haben sollten, wie ein DataFrame funktioniert, können wir uns daran setzen, die `name`-Spalte zu untersuchen. Dies erfordert etwas mehr an Konzentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kann erkennen, dass der Name des Herstellers stets das erste Wort in der Spalte `name` zu sein scheint. Es empfiehlt sich zunächst eine Spalte anzulegen, welche die Namen der Hersteller speichert. Dazu nutzen wir den Accessor `str` der Series. Dieser erlaubt das Ausführen von String-Operationen auf jedem String-Element der Series - und da in einer Series jedes nicht-NaN Element denselben Typ hat und jedes Element dieser Series vom dtype `object` (so bezeichnet Pandas Strings) ist, gilt das auch für jedes einzelne dieser Elemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"oem\"] = df[\"name\"].str.split(\" \", n=1)  # n: Limit der Anzahl an Splits\n",
    "\n",
    "df[\"oem\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir splitten in jeder Zeile, genau einmal (`n=1`), nach Leerzeichen. Um nun lediglich die Namen der Hersteller zu speichern, nutzen wir erneut den `str`-Accessor und _slicen_ ganz einfach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"oem\"] = df[\"oem\"].str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrachten Sie die Series. Fällt Ihnen etwas an ihrem Inhalt auf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"oem\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es existieren mindestens zwei verschiedene Bezeichnungen für die Marke _Chevrolet_ - nämlich `chevrolet` und `chevy`. Dies ist eine Inkonsistenz der Daten. Bevor wir Maßnahmen ergreifen, sollte zunächst geprüft werden, ob so etwas noch häufiger im Datensatz auftritt und falls ja, für welche Hersteller dies der Fall ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"oem\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können folgende Inkonsistenzen feststellen:\n",
    "\n",
    "- Chevrolet: chevrolet, chevy, chevroelt\n",
    "- Volkswagen: volkswagen, vw, vokswagen\n",
    "- Toyota: toyota, toyouta\n",
    "- IH: hi\n",
    "- Mercedes: mercedes-benz, mercedes\n",
    "- Mazda: mazda, maxda\n",
    "\n",
    "Hinzu kommt, dass _capri_ ein **Modell** von _Ford_ ist.\n",
    "\n",
    "Es wäre sinnvoll, wenn jeder Hersteller durchgehend mit ein und derselben Bezeichnung gespeichert ist. Dieser Datenqualitätsmangel lässt sich durch mehrere Wege korrigieren, für die Demonstration sollte einer genügen. Sie können auch selbst mit den Daten experimentieren und eigenständig nach einer Lösung suchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction = {\n",
    "    \"chevy\": \"chevrolet\",\n",
    "    \"chevroelt\": \"chevrolet\",\n",
    "    \"vokswagen\": \"volkswagen\",\n",
    "    \"vw\": \"volkswagen\",\n",
    "    \"toyouta\": \"toyota\",\n",
    "    \"hi\": \"ih\",\n",
    "    \"mercedes-benz\": \"mercedes\",\n",
    "    \"maxda\": \"mazda\",\n",
    "    \"capri\": \"ford\"\n",
    "}\n",
    "\n",
    "df[\"oem\"] = df[\"oem\"].replace(correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"oem\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun haben wir eine separate Spalte mit dem Hersteller für jedes Auto in dem DataFrame. Dadurch können noch mehr Analysen durchgeführt werden. Ab hier können Sie die Analyse und Auswertung der Daten selbstständig und nach Ihren Belieben ausweiten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zwischenstand: Was sollten Sie aus diesem Anwendungsfall mitnehmen?\n",
    "\n",
    "Dieser kleine Anwendungsfall sollte Ihnen ein paar Grundlagen in der Verwendung von Pandas und Plotly vermitteln. Sie sollten nun ein grobes Verständnis dafür haben, wie man mit DataFrames umgehen kann, wie man diese gruppiert, aggregiert und visualisiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Teil 2: Funktionale Programmierung & Datenauswertung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemein\n",
    "\n",
    "Dieser Teil des Übungsblattes beinhaltet Aufgaben, die Sie selbstständig bearbeiten werden. Die Aufgaben vereinen das Thema der funktionalen Programmierung und der Datenauswertung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Funktionale Programmierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1: Pure Functions\n",
    "\n",
    "Programmieren Sie eine Funktion `fahrenheit_to_celsius`, die eine Temperatur in Fahrenheit entgegennimmt und den entsprechenden Wert in Celsius zurückgibt.\n",
    "Die Funktion sollte den folgenden Anforderungen genügen:\n",
    "\n",
    "1. Die Funktion soll rein sein (keine Seiteneffekte).\n",
    "\n",
    "2. Verwenden Sie die Formel $Celsius=(Fahrenheit-32)\\cdot\\frac{5}{9}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmieren Sie hier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erweitern Sie Ihren Code um eine Funktion def `celsius_to_fahrenheit` und testen Sie, ob die beiden Funktionen für gleiche Werte zueinander invers sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2: Higher-Order Functions\n",
    "\n",
    "Implementieren Sie eine Funktion `apply_twice`, die eine andere Funktion und einen Wert als Argumente nimmt und die Funktion zweimal auf den Wert anwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmieren Sie hier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3: Map, Filter, Reduce\n",
    "Verwenden Sie die Funktionen `map`, `filter` und `reduce`, um folgende Aufgaben zu lösen:\n",
    "\n",
    "1. Gegeben eine Liste von Zahlen `numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]`,\n",
    "    - Verdoppeln Sie alle Zahlen (mit `map`).\n",
    "    - Filtern Sie alle geraden Zahlen (mit `filter`).\n",
    "    - Berechnen Sie die Summe der Zahlen (mit `reduce`).\n",
    "2. Schreiben Sie eine Funktion `normalize_names`, die eine Liste von Namen in gemischter Groß- und Kleinschreibung nimmt und eine Liste mit normalisierten Namen (alle klein geschrieben, nur der erste Buchstabe groß) zurückgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmieren Sie hier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2: Bezug zur Datenauswertung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1: Berechnen Sie den durchschnittlichen Kraftstoffverbrauch (mpg) für jedes Herkunftsland mithilfe von `map`, `filter` und `reduce`.\n",
    "\n",
    "**Vorgehen**\n",
    "\n",
    "1. Verwenden Sie `filter`, um die Daten nach Herkunftsland zu filtern.\n",
    "2. Verwenden Sie `map`, um den Kraftstoffverbrauch (`mpg`) für jedes gefilterte Fahrzeug zu extrahieren.\n",
    "3. Verwenden Sie `reduce`, um den durchschnittlichen Kraftstoffverbrauch für jedes Herkunftsland zu berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmieren Sie hier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2: Erstellen Sie eine Funktion, die eine Liste von Fahrzeugnamen entgegennimmt und eine neue Liste zurückgibt, die nur die Namen der Hersteller enthält, die mit \"f\" beginnen.\n",
    "\n",
    "**Vorgehen**\n",
    "\n",
    "1. Verwenden Sie `map`, um den Herstellernamen aus jedem Fahrzeugnamen zu extrahieren (verwenden Sie die Spalte `oem`).\n",
    "2. Verwenden Sie `filter`, um nur die Herstellernamen auszuwählen, die mit \"f\" beginnen.\n",
    "3. Geben Sie die gefilterte Liste zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmieren Sie hier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3: Erstellen Sie eine Funktion, die eine Liste von Fahrzeugnamen entgegennimmt und eine neue Liste zurückgibt, in der alle Herstellernamen in Kleinbuchstaben und der erste Buchstabe großgeschrieben sind (z. B. \"ford\" wird zu \"Ford\").\n",
    "\n",
    "**Vorgehen**\n",
    "\n",
    "1. Verwenden Sie `map`, um die Funktion `capitalize()` auf jeden Herstellernamen in der Liste anzuwenden.\n",
    "2. Geben Sie die neue Liste zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmieren Sie hier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4: Berechnen Sie die Standardabweichung des Gewichts (`weight`) für Fahrzeuge mit mehr als 4 Zylindern mithilfe von `map`, `filter` und `reduce`.\n",
    "\n",
    "**Vorgehen**\n",
    "\n",
    "1. Verwenden Sie `filter`, um die Daten nach Fahrzeugen mit mehr als 4 Zylindern zu filtern.\n",
    "2. Verwenden Sie `map`, um das Gewicht (`weight`) für jedes gefilterte Fahrzeug zu extrahieren.\n",
    "3. Verwenden Sie `reduce` und die Formel für die Standardabweichung, um die Standardabweichung des Gewichts zu berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmieren Sie hier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5: Erstellen Sie eine Funktion, die eine Liste von Fahrzeugnamen entgegennimmt und ein Dictionary zurückgibt, das die Häufigkeit jedes Herstellernamens enthält.\n",
    "\n",
    "**Vorgehen**\n",
    "\n",
    "1. Verwenden Sie `map`, um den Herstellernamen aus jedem Fahrzeugnamen zu extrahieren.\n",
    "2. Erstellen Sie ein leeres Dictionary.\n",
    "3. Iterieren Sie über die Liste der Herstellernamen und erhöhen Sie den Zähler für jeden Namen im Dictionary.\n",
    "4. Geben Sie das Dictionary zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmieren Sie hier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quellen\n",
    "- [Pandas Dokumentation](https://pandas.pydata.org/docs/index.html)\n",
    "- [NumPy Dokumentation](https://numpy.org/doc/)\n",
    "- [Matplotlib Dokumentation](https://numpy.org/doc/)\n",
    "- [SciPy Dokumentation](https://docs.scipy.org/doc/scipy/)\n",
    "- [Scikit-learn API](https://scikit-learn.org/stable/api/index.html)\n",
    "- [Statsmodels API](https://www.statsmodels.org/stable/api.html)\n",
    "- [Seaborn API](https://seaborn.pydata.org/api.html)\n",
    "- [Plotly Dokumentation](https://plotly.github.io/plotly.py-docs/generated/plotly.html)\n",
    "- [Bokeh Dokumentation](https://docs.bokeh.org/en/latest/)\n",
    "- [MPG-Datensatz](https://github.com/mwaskom/seaborn-data/blob/master/mpg.csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
